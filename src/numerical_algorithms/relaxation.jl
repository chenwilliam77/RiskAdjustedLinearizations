"""
```
relaxation!(ral, x‚Çô‚Çã‚ÇÅ, Œ®‚Çô‚Çã‚ÇÅ; tol = 1e-10, max_iters = 1000, damping = .5, pnorm = Inf,
            schur_fnct = schur!, autodiff = :central, use_anderson = false, m = 5,
            verbose = :none, kwargs...)
```

solves for the coefficients ``(z, y, \\Psi)`` of a risk-adjusted linearization by the following relaxation algorithm:

1. Initialize guesses for ``(z, y, \\Psi)``
2. Do until convergence

    a) Solve for ``(z, y)`` using the expectational and state transition equations and fixing ``\\Psi``.

    b) Use a QZ decomposition to solve for ``\\Psi`` while fixing ``(z, y)``.

### Types:
- `S1 <: Number`
- `S2 <: Real`
- `S3 <: Real`

### Inputs
- `m::RiskAdjustedLinearization`: object holding functions needed to calculate
    the risk-adjusted linearization
- `x‚Çô‚Çã‚ÇÅ::AbstractVector{S1}`: initial guess for ``(z, y)``
- `Œ®‚Çô‚Çã‚ÇÅ::AbstractVector{S1}`: initial guess for ``\\Psi``

### Keywords
- `tol::S2`: convergence tolerance of residual norm for relaxation algorithm
- `max_iters::Int`: maximumm number of iterations
- `damping::S2`: guesses are updated as the weighted average
    `x‚Çô = damping * proposal + (1 - damping) * x‚Çô‚Çã‚ÇÅ`.
- `pnorm::S3`: norm for residual tolerance
- `schur_fnct::Function`: function for calculating the Schur factorization during QZ decomposition
- `autodiff::Symbol`: specifies whether to use autoamtic differentiation in `nlsolve`
    (and is the same keyword as the `autodiff` keyword for `nlsolve`)
- `use_anderson::Bool`: set to true to apply Anderson acceleration to the
    fixed point iteration of the relaxation algorithm
- `m::Int`: `m` coefficient if using Anderson acceleration
- `sparse_jacobian::Bool = false`: if true, exploit sparsity in the Jacobian in calls to `nlsolve` using SparseDiffTools.jl.
    If `jac_cache` and `sparsity` are `nothing`, then `relaxation!` will attempt to determine the sparsity pattern.
- `sparsity::Union{AbstractArray, Nothing} = nothing`: sparsity pattern for the Jacobian in calls to `nlsolve`
- `colorvec = nothing`: matrix coloring vector for sparse Jacobian in calls to `nlsolve`
- `jac_cache = nothing`: pre-allocated Jacobian cache for calls to `nlsolve` during the numerical algorithms
- `sparsity_detection::Bool = false`: If true, use SparsityDetection.jl to detect sparsity pattern (only relevant if
    both `jac_cache` and `sparsity` are `nothing`). If false,  then the sparsity pattern is
    determined by using finite differences to calculate a Jacobian and assuming any zeros will always be zero.
    Currently, SparsityDetection.jl fails to work.
- `verbose::Symbol`: verbosity of information printed out during solution.
    a) `:low` -> statement when homotopy continuation succeeds
    b) `:high` -> statement when homotopy continuation succeeds and for each successful iteration
"""
function relaxation!(ral::RiskAdjustedLinearization, x‚Çô‚Çã‚ÇÅ::AbstractVector{S1}, Œ®‚Çô‚Çã‚ÇÅ::AbstractMatrix{S1};
                     tol::S2 = 1e-10, max_iters::Int = 1000, damping::S2 = .5, pnorm::S3 = Inf,
                     schur_fnct::Function = schur!, autodiff::Symbol = :central,
                     use_anderson::Bool = false, m::Int = 5,
                     sparse_jacobian::Bool = false,  sparsity::Union{AbstractArray, Nothing} = nothing,
                     colorvec = nothing, jac_cache = nothing,
                     sparsity_detection::Bool = true, verbose::Symbol = :none,
                     kwargs...) where {S1 <: Number, S2 <: Real, S3 <: Real}
    # Set up
    err = 1.
    nl  = nonlinear_system(ral)
    li  = linearized_system(ral)
    Nzy = ral.Nz + ral.Ny
    AA  = Matrix{Complex{S1}}(undef, Nzy, Nzy) # pre-allocate these matrices to calculate QZ decomp for Œ®
    BB  = similar(AA)

    # Initialize system of equations
    _my_eqn = (F, x, Œ®, ùí±) -> _relaxation_equations(F, x, ral, Œ®, ùí±)

    if use_anderson
        # Some aliases/views will be useful
        z‚Çô    = ral.z
        y‚Çô    = ral.y
        Œ®‚Çô    = ral.Œ®
        ùí±‚Çô‚Çã‚ÇÅ  = nl[:ùí±_sss]
        Jùí±‚Çô‚Çã‚ÇÅ = li[:JV]

        _anderson_f = function _my_anderson(F::AbstractArray{T}, x‚Çô‚Çã‚ÇÅ::AbstractVector{T}) where {T <: Number}
            z‚Çô‚Çã‚ÇÅ  = @view x‚Çô‚Çã‚ÇÅ[1:ral.Nz]
            y‚Çô‚Çã‚ÇÅ  = @view x‚Çô‚Çã‚ÇÅ[(ral.Nz + 1):Nzy]
            Œ®‚Çô‚Çã‚ÇÅ  = @view x‚Çô‚Çã‚ÇÅ[(Nzy + 1):end]
            Œ®‚Çô‚Çã‚ÇÅ  = reshape(Œ®‚Çô‚Çã‚ÇÅ, ral.Ny, ral.Nz)

            # Calculate entropy terms ùí±‚Çô‚Çã‚ÇÅ, Jùí±‚Çô‚Çã‚ÇÅ
            update!(nl, z‚Çô‚Çã‚ÇÅ, y‚Çô‚Çã‚ÇÅ, Œ®‚Çô‚Çã‚ÇÅ; select = Symbol[:ùí±]) # updates nl.ùí±_sss
            update!(li, z‚Çô‚Çã‚ÇÅ, y‚Çô‚Çã‚ÇÅ, Œ®‚Çô‚Çã‚ÇÅ; select = Symbol[:JV]) # updates li.JV

            # Solve state transition and expectational equations for (z‚Çô, y‚Çô), taking ùí±‚Çô‚Çã‚ÇÅ and Œ®‚Çô‚Çã‚ÇÅ as given
            solve_steadystate!(ral, vcat(z‚Çô‚Çã‚ÇÅ, y‚Çô‚Çã‚ÇÅ), _my_eqn, Œ®‚Çô‚Çã‚ÇÅ, ùí±‚Çô‚Çã‚ÇÅ; autodiff = autodiff, # updates ral.z and ral.y
                               sparse_jacobian = sparse_jacobian,
                               sparsity = sparsity, colorvec = colorvec,
                               jac_cache = jac_cache,
                               sparsity_detection = sparsity_detection,
                               verbose = verbose, kwargs...)

            # Update Œì‚ÇÅ, Œì‚ÇÇ, Œì‚ÇÉ, Œì‚ÇÑ, given (z‚Çô, y‚Çô)
            update!(li, z‚Çô, y‚Çô, Œ®‚Çô‚Çã‚ÇÅ; select = Symbol[:Œì‚ÇÅ, :Œì‚ÇÇ, :Œì‚ÇÉ, :Œì‚ÇÑ]) # updates li.Œì·µ¢

            # QZ decomposition to get Œ®‚Çô, taking Œì‚ÇÅ, Œì‚ÇÇ, Œì‚ÇÉ, Œì‚ÇÑ, and Jùí±‚Çô‚Çã‚ÇÅ as given
            Œ®‚Çô .= compute_Œ®!(AA, BB, li; schur_fnct = schur_fnct)

            # Update z‚Çô, y‚Çô, and Œ®‚Çô; then calculate error for convergence check
            z‚Çô .= (1 - damping) .* z‚Çô + damping .* z‚Çô‚Çã‚ÇÅ
            y‚Çô .= (1 - damping) .* y‚Çô + damping .* y‚Çô‚Çã‚ÇÅ
            Œ®‚Çô .= (1 - damping) .* Œ®‚Çô + damping .* Œ®‚Çô‚Çã‚ÇÅ
            err = norm(vcat(z‚Çô - z‚Çô‚Çã‚ÇÅ, y‚Çô - y‚Çô‚Çã‚ÇÅ, vec(Œ®‚Çô - Œ®‚Çô‚Çã‚ÇÅ)), pnorm)

            # Calculate residual
            F[1:ral.Nz] = z‚Çô - z‚Çô‚Çã‚ÇÅ
            F[(ral.Nz + 1):Nzy] = y‚Çô - y‚Çô‚Çã‚ÇÅ
            F[(Nzy + 1):end] = vec(Œ®‚Çô - Œ®‚Çô‚Çã‚ÇÅ)

            return F
        end

        out   = nlsolve(_anderson_f, vcat(x‚Çô‚Çã‚ÇÅ, vec(Œ®‚Çô‚Çã‚ÇÅ)); m = m, ftol = tol, iterations = max_iters)
        count = out.iterations
        if out.f_converged
            update!(ral, out.zero[1:ral.Nz], out.zero[(ral.Nz + 1):Nzy],
                    reshape(out.zero[(Nzy + 1):end], ral.Ny, ral.Nz); update_cache = false)
        end
    else
        count = 1

        # Some aliases/views will be useful
        z‚Çô‚Çã‚ÇÅ  = @view x‚Çô‚Çã‚ÇÅ[1:ral.Nz]
        y‚Çô‚Çã‚ÇÅ  = @view x‚Çô‚Çã‚ÇÅ[(ral.Nz + 1):end]
        z‚Çô    = ral.z
        y‚Çô    = ral.y
        Œ®‚Çô    = ral.Œ®
        ùí±‚Çô‚Çã‚ÇÅ  = nl[:ùí±_sss]
        Jùí±‚Çô‚Çã‚ÇÅ = li[:JV]

        while (err > tol) && (count < max_iters)

            # Calculate entropy terms ùí±‚Çô‚Çã‚ÇÅ, Jùí±‚Çô‚Çã‚ÇÅ
            update!(nl, z‚Çô‚Çã‚ÇÅ, y‚Çô‚Çã‚ÇÅ, Œ®‚Çô‚Çã‚ÇÅ; select = Symbol[:ùí±]) # updates nl.ùí±_sss
            update!(li, z‚Çô‚Çã‚ÇÅ, y‚Çô‚Çã‚ÇÅ, Œ®‚Çô‚Çã‚ÇÅ; select = Symbol[:JV]) # updates li.JV

            # Solve state transition and expectational equations for (z‚Çô, y‚Çô), taking ùí±‚Çô‚Çã‚ÇÅ and Œ®‚Çô‚Çã‚ÇÅ as given
            solve_steadystate!(ral, x‚Çô‚Çã‚ÇÅ, _my_eqn, Œ®‚Çô‚Çã‚ÇÅ, ùí±‚Çô‚Çã‚ÇÅ; autodiff = autodiff, # updates ral.z and ral.y
                               sparse_jacobian = sparse_jacobian,
                               sparsity = sparsity, colorvec = colorvec,
                               jac_cache = jac_cache,
                               sparsity_detection = sparsity_detection,
                               verbose = verbose, kwargs...)

            # Update Œì‚ÇÅ, Œì‚ÇÇ, Œì‚ÇÉ, Œì‚ÇÑ, given (z‚Çô, y‚Çô)
            update!(li, z‚Çô, y‚Çô, Œ®‚Çô‚Çã‚ÇÅ; select = Symbol[:Œì‚ÇÅ, :Œì‚ÇÇ, :Œì‚ÇÉ, :Œì‚ÇÑ]) # updates li.Œì·µ¢

            # QZ decomposition to get Œ®‚Çô, taking Œì‚ÇÅ, Œì‚ÇÇ, Œì‚ÇÉ, Œì‚ÇÑ, and Jùí±‚Çô‚Çã‚ÇÅ as given
            Œ®‚Çô .= compute_Œ®!(AA, BB, li; schur_fnct = schur_fnct)

            # Update z‚Çô, y‚Çô, and Œ®‚Çô; then calculate error for convergence check
            z‚Çô .= (1 - damping) .* z‚Çô + damping .* z‚Çô‚Çã‚ÇÅ
            y‚Çô .= (1 - damping) .* y‚Çô + damping .* y‚Çô‚Çã‚ÇÅ
            Œ®‚Çô .= (1 - damping) .* Œ®‚Çô + damping .* Œ®‚Çô‚Çã‚ÇÅ
            err = norm(vcat(z‚Çô - z‚Çô‚Çã‚ÇÅ, y‚Çô - y‚Çô‚Çã‚ÇÅ, vec(Œ®‚Çô - Œ®‚Çô‚Çã‚ÇÅ)), pnorm)

            # Update z‚Çô‚Çã‚ÇÅ, y‚Çô‚Çã‚ÇÅ, and Œ®‚Çô‚Çã‚ÇÅ (without reallocating them)
            z‚Çô‚Çã‚ÇÅ .= z‚Çô
            y‚Çô‚Çã‚ÇÅ .= y‚Çô
            Œ®‚Çô‚Çã‚ÇÅ .= Œ®‚Çô

            if verbose == :high
                println("Iteration $(count): error under norm=$(pnorm) is $(err)")
            end

            count += 1
        end
    end

    if count == max_iters
        throw(RALRelaxationError("Relaxation method to find the risk-adjusted linearization did not converge."))
    else
        update!(ral)

        if verbose == :low
            errvec = steady_state_errors(ral)
            println("Convergence achieved after $(count) iterations! Error under norm = $(pnorm) is " *
                    "$(norm(errvec, pnorm)).")
        elseif verbose == :high
            errvec = steady_state_errors(ral)
            println("")
            println("Convergence achieved after $(count) iterations! Error under norm = $(pnorm) is " *
                    "$(norm(errvec, pnorm)).")
        end

        return ral
    end
end

function solve_steadystate!(m::RiskAdjustedLinearization, x0::AbstractVector{S1},
                            f::Function, Œ®::AbstractMatrix{<: Number}, ùí±::AbstractVector{<: Number};
                            sparse_jacobian::Bool = false, sparsity::Union{AbstractArray, Nothing} = nothing,
                            colorvec = nothing, jac_cache = nothing,
                            sparsity_detection::Bool = true, autodiff::Symbol = :central,
                            verbose::Symbol = :none, kwargs...) where {S1 <: Real, S2 <: Real}

    # Exploit sparsity?
    if sparse_jacobian
        nlsolve_jacobian!, jac =
            construct_sparse_jacobian_function(m, (F, x) -> f(F, x, Œ®, ùí±), :relaxation, autodiff;
                                               sparsity = sparsity, colorvec = colorvec,
                                               jac_cache = jac_cache, sparsity_detection = sparsity_detection)
        out = nlsolve(OnceDifferentiable((F, x) -> f(F, x, Œ®, ùí±), nlsolve_jacobian!, x0, copy(x0), jac), x0; kwargs...)
    else
        out = nlsolve(OnceDifferentiable((F, x) -> f(F, x, Œ®, ùí±), x0, copy(x0), autodiff,
                                         ForwardDiff.Chunk(ForwardDiff.pickchunksize(min(m.Nz, m.Ny)))), x0; kwargs...)
    end

    if out.f_converged
        m.z .= out.zero[1:m.Nz]
        m.y .= out.zero[(m.Nz + 1):end]
    else
        if verbose == :high
            println(out)
        end
        throw(RALRelaxationError())
    end
end

function _relaxation_equations(F::AbstractArray, x::AbstractArray, m::RiskAdjustedLinearization,
                               Œ®::AbstractMatrix{<: Number}, ùí±::AbstractVector{<: Number})
    # Unpack
    z = @view x[1:m.Nz]
    y = @view x[(m.Nz + 1):end]

    # Update Œº(z, y) and Œæ(z, y)
    update!(m.nonlinear, z, y, Œ®; select = Symbol[:Œº, :Œæ])

    # Calculate residuals
    Œº_sss             = get_tmp(m.nonlinear.Œº.cache, z, y, (1, 1)) # select the first DiffCache b/c that one
    Œæ_sss             = get_tmp(m.nonlinear.Œæ.cache, z, y, (1, 1)) # corresponds to autodiffing both z and y
    F[1:m.Nz]         = Œº_sss - z
    F[(m.Nz + 1):end] = Œæ_sss + m.linearization[:Œì‚ÇÖ] * z + m.linearization[:Œì‚ÇÜ] * y + ùí±
end

mutable struct RALRelaxationError <: Exception
    msg::String
end
RALRelaxationError() =
    RALRelaxationError("A solution for (z, y), given Œ® and ùí±, to the state transition and expectational equations could not be found.")
Base.showerror(io::IO, ex::RALRelaxationError) = print(io, ex.msg)
